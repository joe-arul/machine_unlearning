{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# For-Debugging Notebook\n## Contributed by Kaggle user - hmasdev\n\nRun unlearning function on CIFAR10 dataset (format similar to competition dataset) and generate 5 checkpoints ","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\n\nimport pandas as pd\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet18\nfrom torch.utils.data import DataLoader, Dataset\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \nDEVICE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-09T04:00:32.199930Z","iopub.execute_input":"2023-11-09T04:00:32.200288Z","iopub.status.idle":"2023-11-09T04:00:32.527599Z","shell.execute_reply.started":"2023-11-09T04:00:32.200260Z","shell.execute_reply":"2023-11-09T04:00:32.526648Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"torch.manual_seed(128)\n\nGr = torch.Generator()\nGr.manual_seed(256)\n\nGf = torch.Generator()\nGf.manual_seed(512)\n\nGv = torch.Generator()\nGv.manual_seed(1024)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:00:35.189039Z","iopub.execute_input":"2023-11-09T04:00:35.189504Z","iopub.status.idle":"2023-11-09T04:00:35.207326Z","shell.execute_reply.started":"2023-11-09T04:00:35.189477Z","shell.execute_reply":"2023-11-09T04:00:35.206437Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7af6e0fa4bf0>"},"metadata":{}}]},{"cell_type":"code","source":"# Mock setting\n\nimport logging\nimport requests\nimport tqdm\nfrom torch.utils.data import Subset\nfrom torchvision import transforms\n\nUSE_MOCK: bool = True\n\nif USE_MOCK:\n    logging.warning('Running with Mock')\n    logging.warning('In this mode, internet access may be required.')\n\n    # The number of checkpoints in this mode.\n    # NOTE: 512 checkpoints are required in this competition.\n    n_checkpoints = 5\n    \n    # The directory for a dataset and a pretrained model\n    mock_dir = './mock'\n    mock_model_path = os.path.join(mock_dir, \"weights_resnet18_cifar10.pth\")\n    os.makedirs(mock_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:00:39.767428Z","iopub.execute_input":"2023-11-09T04:00:39.767798Z","iopub.status.idle":"2023-11-09T04:00:39.774355Z","shell.execute_reply.started":"2023-11-09T04:00:39.767768Z","shell.execute_reply":"2023-11-09T04:00:39.773392Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\n# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\n\nif DEVICE != 'cuda':\n    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:00:44.620314Z","iopub.execute_input":"2023-11-09T04:00:44.620958Z","iopub.status.idle":"2023-11-09T04:00:44.627934Z","shell.execute_reply.started":"2023-11-09T04:00:44.620913Z","shell.execute_reply":"2023-11-09T04:00:44.626677Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Helper functions for loading the hidden dataset.\n\nif USE_MOCK:\n    \n    class DatasetWrapper(Dataset):\n        \n        def __init__(self, ds: Dataset):\n            self._ds = ds\n    \n        def __len__(self):\n            return len(self._ds)\n    \n        def __getitem__(self, index):\n            item = self._ds[index]\n            result = {\n                'image': item[0],\n                'image_id': index,\n                'age_group': item[1],\n                'age': item[1],\n                'person_id': index,\n            }\n            return result\n    \n    def get_dataset(batch_size, retain_ratio=0.8, thinning_param: int=1000, root=mock_dir) -> tuple[DataLoader, DataLoader, DataLoader]:\n        \n        # utils\n        normalize = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ])\n\n        # create dataset\n        train_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=True, download=True, transform=normalize))\n        retain_ds = Subset(train_ds, range(0, int(len(train_ds)*retain_ratio), thinning_param))\n        forget_ds = Subset(train_ds, range(int(len(train_ds)*retain_ratio), len(train_ds), thinning_param))\n        val_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=False, download=True, transform=normalize))\n\n        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n\n        return retain_loader, forget_loader, validation_loader\nelse:\n    def load_example(df_row):\n        image = torchvision.io.read_image(df_row['image_path'])\n        result = {\n            'image': image,\n            'image_id': df_row['image_id'],\n            'age_group': df_row['age_group'],\n            'age': df_row['age'],\n            'person_id': df_row['person_id']\n        }\n        return result\n\n\n    class HiddenDataset(Dataset):\n        '''The hidden dataset.'''\n        def __init__(self, split='train'):\n            super().__init__()\n            self.examples = []\n\n            df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n            df['image_path'] = df['image_id'].apply(lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n            df = df.sort_values(by='image_path')\n            df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n            if len(self.examples) == 0:\n                raise ValueError('No examples.')\n\n        def __len__(self):\n            return len(self.examples)\n\n        def __getitem__(self, idx):\n            example = self.examples[idx]\n            image = example['image']\n            image = image.to(torch.float32)\n            example['image'] = image\n            return example\n\n    def get_dataset(batch_size):\n\n        retain_ds = HiddenDataset(split='retain')\n        forget_ds = HiddenDataset(split='forget')\n        val_ds = HiddenDataset(split='validation')\n\n        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True, generator=Gr)\n        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True, generator=Gf)\n        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=Gv)\n\n        return retain_loader, forget_loader, validation_loader","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:00:46.671641Z","iopub.execute_input":"2023-11-09T04:00:46.671991Z","iopub.status.idle":"2023-11-09T04:00:46.690548Z","shell.execute_reply.started":"2023-11-09T04:00:46.671962Z","shell.execute_reply":"2023-11-09T04:00:46.689681Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Utils\nfrom contextlib import contextmanager\nimport time\n\n@contextmanager\ndef stopwatch(name='STOPWATCH'):\n    s = time.time()\n    try:\n        yield\n    finally:\n        print(f\"{name}: {time.time()-s} seconds passed\")","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:00:54.592520Z","iopub.execute_input":"2023-11-09T04:00:54.592887Z","iopub.status.idle":"2023-11-09T04:00:54.598471Z","shell.execute_reply.started":"2023-11-09T04:00:54.592857Z","shell.execute_reply":"2023-11-09T04:00:54.597460Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import copy\nimport itertools\nfrom tqdm import tqdm\n\ndef unlearning(\n    net, \n    retain_loader, \n    forget_loader, \n    val_loader):\n\n    epochs = 10\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.005,\n                      momentum=0.9, weight_decay=5e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=epochs)\n    \n    net.train()\n\n    for ep in range(epochs):\n        \n        net.train()\n        for sample in tqdm(retain_loader):\n            inputs = sample[\"image\"]\n            targets = sample[\"age_group\"]\n            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n        \n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n        scheduler.step()\n        \n    net.eval()\n    return net","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:08:58.106489Z","iopub.execute_input":"2023-11-09T04:08:58.107213Z","iopub.status.idle":"2023-11-09T04:08:58.115072Z","shell.execute_reply.started":"2023-11-09T04:08:58.107172Z","shell.execute_reply":"2023-11-09T04:08:58.114131Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"%%time\n\nif USE_MOCK:\n    \n    # Download\n    if not os.path.exists(mock_model_path):\n        response = requests.get(\"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\")\n        open(mock_model_path, \"wb\").write(response.content)    \n    \n    os.makedirs('/kaggle/tmp', exist_ok=True)\n    retain_loader, forget_loader, validation_loader = get_dataset(128)\n    net = resnet18(weights=None, num_classes=10)\n    net.to(DEVICE)\n    for i in range(n_checkpoints):\n        net.load_state_dict(torch.load(mock_model_path))\n        net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n        state = net_.state_dict()\n        torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n\n    unlearned_ckpts = os.listdir('/kaggle/tmp')\n    if len(unlearned_ckpts) != n_checkpoints:\n        raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n\n    subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n    \nelse:\n    if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n        # mock submission\n        subprocess.run('touch submission.zip', shell=True)\n    else:\n\n        # Note: it's really important to create the unlearned checkpoints outside of the working directory \n        # as otherwise this notebook may fail due to running out of disk space.\n        # The below code saves them in /kaggle/tmp to avoid that issue.\n\n        os.makedirs('/kaggle/tmp', exist_ok=True)\n        retain_loader, forget_loader, validation_loader = get_dataset(64)\n        net = resnet18(weights=None, num_classes=10)\n        net.to(DEVICE)\n        for i in range(512):\n            net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n            net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n            state = net_.state_dict()\n            torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n\n        # Ensure that submission.zip will contain exactly 512 checkpoints \n        # (if this is not the case, an exception will be thrown).\n        unlearned_ckpts = os.listdir('/kaggle/tmp')\n        if len(unlearned_ckpts) != 512:\n            raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n\n        subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T04:09:00.294638Z","iopub.execute_input":"2023-11-09T04:09:00.294979Z","iopub.status.idle":"2023-11-09T04:09:14.845948Z","shell.execute_reply.started":"2023-11-09T04:09:00.294950Z","shell.execute_reply":"2023-11-09T04:09:14.844980Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 43.24it/s]\n100%|██████████| 1/1 [00:00<00:00, 51.86it/s]\n100%|██████████| 1/1 [00:00<00:00, 45.92it/s]\n100%|██████████| 1/1 [00:00<00:00, 51.66it/s]\n100%|██████████| 1/1 [00:00<00:00, 48.29it/s]\n100%|██████████| 1/1 [00:00<00:00, 43.62it/s]\n100%|██████████| 1/1 [00:00<00:00, 41.73it/s]\n100%|██████████| 1/1 [00:00<00:00, 44.29it/s]\n100%|██████████| 1/1 [00:00<00:00, 49.25it/s]\n100%|██████████| 1/1 [00:00<00:00, 55.06it/s]\n100%|██████████| 1/1 [00:00<00:00, 49.72it/s]\n100%|██████████| 1/1 [00:00<00:00, 47.69it/s]\n100%|██████████| 1/1 [00:00<00:00, 53.29it/s]\n100%|██████████| 1/1 [00:00<00:00, 48.23it/s]\n100%|██████████| 1/1 [00:00<00:00, 51.72it/s]\n100%|██████████| 1/1 [00:00<00:00, 57.80it/s]\n100%|██████████| 1/1 [00:00<00:00, 42.38it/s]\n100%|██████████| 1/1 [00:00<00:00, 57.33it/s]\n100%|██████████| 1/1 [00:00<00:00, 46.53it/s]\n100%|██████████| 1/1 [00:00<00:00, 55.34it/s]\n100%|██████████| 1/1 [00:00<00:00, 44.10it/s]\n100%|██████████| 1/1 [00:00<00:00, 54.54it/s]\n100%|██████████| 1/1 [00:00<00:00, 54.49it/s]\n100%|██████████| 1/1 [00:00<00:00, 53.95it/s]\n100%|██████████| 1/1 [00:00<00:00, 55.58it/s]\n100%|██████████| 1/1 [00:00<00:00, 52.12it/s]\n100%|██████████| 1/1 [00:00<00:00, 49.79it/s]\n100%|██████████| 1/1 [00:00<00:00, 52.18it/s]\n100%|██████████| 1/1 [00:00<00:00, 56.16it/s]\n100%|██████████| 1/1 [00:00<00:00, 56.60it/s]\n100%|██████████| 1/1 [00:00<00:00, 45.98it/s]\n100%|██████████| 1/1 [00:00<00:00, 53.87it/s]\n100%|██████████| 1/1 [00:00<00:00, 56.91it/s]\n100%|██████████| 1/1 [00:00<00:00, 60.66it/s]\n100%|██████████| 1/1 [00:00<00:00, 59.11it/s]\n100%|██████████| 1/1 [00:00<00:00, 49.12it/s]\n100%|██████████| 1/1 [00:00<00:00, 56.48it/s]\n100%|██████████| 1/1 [00:00<00:00, 50.01it/s]\n100%|██████████| 1/1 [00:00<00:00, 54.50it/s]\n100%|██████████| 1/1 [00:00<00:00, 48.54it/s]\n100%|██████████| 1/1 [00:00<00:00, 42.54it/s]\n100%|██████████| 1/1 [00:00<00:00, 43.64it/s]\n100%|██████████| 1/1 [00:00<00:00, 52.67it/s]\n100%|██████████| 1/1 [00:00<00:00, 48.11it/s]\n100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n100%|██████████| 1/1 [00:00<00:00, 56.94it/s]\n100%|██████████| 1/1 [00:00<00:00, 50.59it/s]\n100%|██████████| 1/1 [00:00<00:00, 54.41it/s]\n100%|██████████| 1/1 [00:00<00:00, 54.56it/s]\n100%|██████████| 1/1 [00:00<00:00, 57.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/tmp/unlearned_checkpoint_0.pth (deflated 6%)\n  adding: kaggle/tmp/unlearned_checkpoint_1.pth (deflated 6%)\n  adding: kaggle/tmp/unlearned_checkpoint_2.pth (deflated 6%)\n  adding: kaggle/tmp/unlearned_checkpoint_3.pth (deflated 6%)\n  adding: kaggle/tmp/unlearned_checkpoint_4.pth (deflated 6%)\nCPU times: user 3.03 s, sys: 540 ms, total: 3.57 s\nWall time: 14.5 s\n","output_type":"stream"}]}]}