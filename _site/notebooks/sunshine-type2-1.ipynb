{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8477aea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-09T04:32:29.682196Z",
     "iopub.status.busy": "2023-11-09T04:32:29.681311Z",
     "iopub.status.idle": "2023-11-09T04:32:34.217799Z",
     "shell.execute_reply": "2023-11-09T04:32:34.216777Z"
    },
    "papermill": {
     "duration": 4.544241,
     "end_time": "2023-11-09T04:32:34.220321",
     "exception": false,
     "start_time": "2023-11-09T04:32:29.676080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7aa9a1",
   "metadata": {
    "papermill": {
     "duration": 0.00298,
     "end_time": "2023-11-09T04:32:34.226841",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.223861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use GPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b77218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T04:32:34.234377Z",
     "iopub.status.busy": "2023-11-09T04:32:34.233883Z",
     "iopub.status.idle": "2023-11-09T04:32:34.238141Z",
     "shell.execute_reply": "2023-11-09T04:32:34.237259Z"
    },
    "papermill": {
     "duration": 0.010303,
     "end_time": "2023-11-09T04:32:34.240019",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.229716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEVICE != 'cuda':\n",
    "    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eead38e",
   "metadata": {
    "papermill": {
     "duration": 0.002684,
     "end_time": "2023-11-09T04:32:34.245722",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.243038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions for loading hidden dataset\n",
    "\n",
    "- Location of dataset : /kaggle/input/neurips-2023-machine-unlearning/\n",
    "- Contents of each record: Image, Image ID, Age roup (Target), Age, Person ID\n",
    "- retain.csv, forget.csv, validation.csv provided by competition\n",
    "- Use dataset loader with shuffle=True (to include randomness between different runs - 512 different checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628fa65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T04:32:34.253265Z",
     "iopub.status.busy": "2023-11-09T04:32:34.252932Z",
     "iopub.status.idle": "2023-11-09T04:32:34.265122Z",
     "shell.execute_reply": "2023-11-09T04:32:34.264173Z"
    },
    "papermill": {
     "duration": 0.018463,
     "end_time": "2023-11-09T04:32:34.267159",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.248696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_example(df_row):\n",
    "    \n",
    "    image = torchvision.io.read_image(df_row['image_path'])\n",
    "    # For each person, the following information is available\n",
    "    result = {\n",
    "        'image': image,\n",
    "        'image_id': df_row['image_id'],\n",
    "        'age_group': df_row['age_group'],\n",
    "        'age': df_row['age'],\n",
    "        'person_id': df_row['person_id']\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "class HiddenDataset(Dataset):\n",
    "\n",
    "    def __init__(self, split='train'):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.examples = []\n",
    "        # location of Dataset + type of data\n",
    "        df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n",
    "        \n",
    "        # Using Image IDs, retrieve images\n",
    "        df['image_path'] = df['image_id'].apply(\n",
    "            lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "        df = df.sort_values(by='image_path')\n",
    "        \n",
    "        # Split records for each individual\n",
    "        df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n",
    "        \n",
    "        if len(self.examples) == 0:\n",
    "            raise ValueError('No examples.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        image = example['image']\n",
    "        image = image.to(torch.float32)\n",
    "        example['image'] = image\n",
    "        return example\n",
    "\n",
    "\n",
    "def get_dataset(batch_size):\n",
    "    \n",
    "    # Load data for Retain, Forget and Validation datasets\n",
    "    retain_ds = HiddenDataset(split='retain')\n",
    "    forget_ds = HiddenDataset(split='forget')\n",
    "    val_ds = HiddenDataset(split='validation')\n",
    "\n",
    "    # Use dataloader to save RAM\n",
    "    retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n",
    "    forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return retain_loader, forget_loader, validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74371aeb",
   "metadata": {
    "papermill": {
     "duration": 0.002829,
     "end_time": "2023-11-09T04:32:34.273206",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.270377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unlearning operation\n",
    "Strategy 2: Using a negative gradient on the forgetting samples\n",
    "\n",
    "- 25 epochs\n",
    "- Optimizer : SGD\n",
    "- Learning rate : 0.005, weight_decay = 5e-4\n",
    "- Scheduler : Cosine Annealing\n",
    "- Dataset : Forget samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc109ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T04:32:34.281079Z",
     "iopub.status.busy": "2023-11-09T04:32:34.280259Z",
     "iopub.status.idle": "2023-11-09T04:32:34.288304Z",
     "shell.execute_reply": "2023-11-09T04:32:34.287361Z"
    },
    "papermill": {
     "duration": 0.014042,
     "end_time": "2023-11-09T04:32:34.290218",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.276176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unlearning(\n",
    "    net, \n",
    "    retain_loader, \n",
    "    forget_loader, \n",
    "    val_loader):\n",
    "\n",
    "    epochs = 25\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=epochs)\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        \n",
    "        net.train()\n",
    "        for sample in forget_loader:\n",
    "            inputs = sample[\"image\"]\n",
    "            targets = sample[\"age_group\"]\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = -(criterion(outputs, targets))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c1641",
   "metadata": {
    "papermill": {
     "duration": 0.002959,
     "end_time": "2023-11-09T04:32:34.296444",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.293485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Access dataset, load model, call unlearning function and generate submission file with unlearned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55399716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T04:32:34.304699Z",
     "iopub.status.busy": "2023-11-09T04:32:34.304019Z",
     "iopub.status.idle": "2023-11-09T04:32:34.320045Z",
     "shell.execute_reply": "2023-11-09T04:32:34.319095Z"
    },
    "papermill": {
     "duration": 0.022608,
     "end_time": "2023-11-09T04:32:34.322349",
     "exception": false,
     "start_time": "2023-11-09T04:32:34.299741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dummy pathway for local - does not exist in submission\n",
    "if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "    subprocess.run('touch submission.zip', shell=True)\n",
    "    \n",
    "else:\n",
    "    # tmp directory - cannot save in home dir\n",
    "    os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "    # batch size - 128\n",
    "    retain_loader, forget_loader, validation_loader = get_dataset(128)\n",
    "    # load model template\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE)\n",
    "    # load model and call unlearning function 512 times\n",
    "    for i in range(512):\n",
    "        net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n",
    "        unlearning(net, retain_loader, forget_loader, validation_loader)\n",
    "        state = net.state_dict()\n",
    "        # save as checkpoint\n",
    "        torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
    "        \n",
    "    # Ensure that submission.zip will contain exactly 512 checkpoints \n",
    "    # (if this is not the case, an exception will be thrown).\n",
    "    unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "    if len(unlearned_ckpts) != 512:\n",
    "        raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
    "    # zip it and create submission\n",
    "    subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.382859,
   "end_time": "2023-11-09T04:32:35.647109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-09T04:32:26.264250",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
